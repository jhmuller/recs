{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "537bd595",
   "metadata": {},
   "source": [
    "https://betterprogramming.pub/building-a-recommendation-engine-with-pytorch-d64be4856fe7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efc9817a",
   "metadata": {},
   "source": [
    "# Embeddings for Recommendations\n",
    "\n",
    "Here I use a move rating data set from Kaggle.\n",
    "In this notebook I will derive embeddings for users and movies\n",
    "and these will be the ingredients of a matrix factorization\n",
    "of the full rating matrix.\n",
    "\n",
    "We will train a simple Neural Net using Pytorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b2313637",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch.cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d89d633f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9fb9dffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "!export CUDA_LAUNCH_BLOCKING=1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "002f08c1",
   "metadata": {},
   "source": [
    "### Note: I am going to use my GPU card ... or try to anyway."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9c1a4b36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device in use: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"Device in use:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e216cfa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Read in the data and show shape and head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6996373a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(26024289, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>110</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1425941529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>147</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1425942435</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  movieId  rating   timestamp\n",
       "0       1      110     1.0  1425941529\n",
       "1       1      147     4.5  1425942435"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"ratings.csv\")\n",
    "print(df.shape)\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c33f3eb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max userId 270896 num users 270896\n",
      "max movieId 176275 num movies 45115\n"
     ]
    }
   ],
   "source": [
    "print(f\"max userId {df.userId.max()} num users {df.userId.nunique()}\")\n",
    "print(f\"max movieId {df.movieId.max()} num movies {df.movieId.nunique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "398b54ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max userId 49999 num users 49601\n",
      "max movieId 4999 num movies 4896\n",
      "(3370149, 4)\n"
     ]
    }
   ],
   "source": [
    "subsample = True\n",
    "if subsample:\n",
    "    max_user = 50000\n",
    "    max_movie = 5000\n",
    "    df = df.loc[df.movieId < max_movie]\n",
    "    df = df.loc[df.userId < max_user]\n",
    "    print(f\"max userId {df.userId.max()} num users {df.userId.nunique()}\")\n",
    "    print(f\"max movieId {df.movieId.max()} num movies {df.movieId.nunique()}\")    \n",
    "    print(df.shape)    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b978048f",
   "metadata": {},
   "source": [
    "## Partition the dataset\n",
    "into train, val and test.\n",
    "We can use val to tune the hyper parameters.\n",
    "\n",
    "Test will be held out until all training is done.\n",
    "\n",
    "We could use the sklearn function but I find this just as easy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f1aac548",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2665.841796875"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def partition(df, pct=0.1):\n",
    "    size = int(np.floor(df.shape[0])*0.1)\n",
    "    idx = list(np.random.choice(df.index, size, replace=False))\n",
    "    subset = df.filter(items=idx, axis=0)\n",
    "    rest = df.drop(index = idx)\n",
    "    return subset, rest\n",
    "\n",
    "testdf, val_train = partition(df, 0.1)\n",
    "valdf, traindf = partition(val_train, 0.2)\n",
    "traindf.shape[0] / 1024"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3f59253",
   "metadata": {},
   "source": [
    "## Dataset and dataloader\n",
    "I want to use mini-batch training so we need a dataset\n",
    "and a dataloader.\n",
    "\n",
    "I adapted some code for converting a pandas dataframe into a dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "599bfbfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, dataframe):\n",
    "        self.dataframe = dataframe\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        row = self.dataframe.iloc[index].to_numpy()\n",
    "        userid = int(row[0])\n",
    "        movieid = int(row[1])\n",
    "        rating = np.float32(row[2])\n",
    "        return userid, movieid, rating\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "\n",
    "traindata = CustomDataset(dataframe=traindf)\n",
    "train_dataloader = DataLoader(traindata, batch_size=1024, pin_memory=True)\n",
    "\n",
    "valdata = CustomDataset(dataframe=valdf)\n",
    "val_dataloader = DataLoader(valdata, batch_size=512, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "fd43d11d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x7f61b3aa2f50>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8e14b13",
   "metadata": {},
   "source": [
    "## the Model\n",
    "The model is fairly simple: 2 embedding layers, \n",
    "    one each for users and movies.\n",
    "    \n",
    "At the end of \"froward\" we simply do the dot product."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d4e8e124",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MF(nn.Module):\n",
    "    def __init__(self, n_users, n_movies, emb_size=100):\n",
    "        super(MF, self).__init__()\n",
    "        self.n_users = n_users\n",
    "        self.n_movies = n_movies\n",
    "        self.user_emb = nn.Embedding(n_users, emb_size)\n",
    "        self.movie_emb = nn.Embedding(n_movies, emb_size)\n",
    "        # initializing our matrices with a positive number generally will yield better results\n",
    "        self.user_emb.weight.data.uniform_(0, 0.5)\n",
    "        self.movie_emb.weight.data.uniform_(0, 0.5)\n",
    "    def forward(self, users, movies):\n",
    "        #print(\"in forward\")\n",
    "        #print(users.max(), users.shape, movies.max(), movies.shape)\n",
    "        #print(n_users, n_movies)\n",
    "        m = self.movie_emb(movies)\n",
    "        u = self.user_emb(users)\n",
    "        return (u * m).sum(1)  # taking the dot product\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99c0ff82",
   "metadata": {},
   "source": [
    "## instantiate the Model\n",
    "and push it to the gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "eaacc2e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_CUDA = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2ec19318",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000 9020\n",
      "using cuda\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "n_users = df.userId.max()+1\n",
    "n_movies = df.movieId.max()+1\n",
    "print(n_users, n_movies)\n",
    "model = MF(n_users, n_movies, emb_size=100)\n",
    "use_cuda = False\n",
    "if USE_CUDA:\n",
    "    if torch.cuda.is_available():\n",
    "        print(\"using cuda\")\n",
    "        model = model.to(device)\n",
    "print(next(model.parameters()).is_cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1a3e05a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MF(\n",
       "  (user_emb): Embedding(50000, 100)\n",
       "  (movie_emb): Embedding(9020, 100)\n",
       ")"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2196c2a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " epoch 0\n",
      " batch 0 0.0\n",
      " batch 10 0.03091328125\n",
      " batch 20 0.05743164062499999\n",
      " batch 30 0.08576503906249999\n",
      " batch 40 0.11526445312499999\n",
      " batch 50 0.15070878906249996\n",
      " batch 60 0.17968417968749997\n",
      " batch 70 0.22663320312499996\n",
      " batch 80 0.273773046875\n",
      " batch 90 0.31269394531249994\n",
      " batch 100 0.3627755859374999\n",
      " batch 110 0.40634375\n",
      " batch 120 0.4614003906249999\n",
      " batch 130 0.520915234375\n",
      " batch 140 0.5756519531250001\n",
      " batch 150 0.6341634765625002\n",
      " batch 160 0.7001457031250002\n",
      " batch 170 0.7647980468750003\n",
      " batch 180 0.8303585937500003\n",
      " batch 190 0.8916527343750005\n",
      " batch 200 0.9623736328125004\n",
      " batch 210 1.0459083984375006\n",
      " batch 220 1.116830468750001\n",
      " batch 230 1.2067304687500011\n",
      " batch 240 1.2991796875000008\n",
      " batch 250 1.368230273437501\n",
      " batch 260 1.436738281250001\n",
      " batch 270 1.516301757812501\n",
      " batch 280 1.5970746093750012\n",
      " batch 290 1.6763718750000012\n",
      " batch 300 1.7560130859375012\n",
      " batch 310 1.8412138671875007\n",
      " batch 320 1.9420212890625008\n",
      " batch 330 2.0597363281250014\n",
      " batch 340 2.1445957031250016\n",
      " batch 350 2.269754687500002\n",
      " batch 360 2.389090625000003\n",
      " batch 370 2.4864962890625026\n",
      " batch 380 2.5887300781250024\n",
      " batch 390 2.685974609375002\n",
      " batch 400 2.781557812500002\n",
      " batch 410 2.894825585937502\n",
      " batch 420 2.976722265625002\n",
      " batch 430 3.0725558593750018\n",
      " batch 440 3.207462109375001\n",
      " batch 450 3.3253246093750013\n",
      " batch 460 3.4547486328125014\n",
      " batch 470 3.5459648437500015\n",
      " batch 480 3.682456835937502\n",
      " batch 490 3.7995464843750018\n",
      " batch 500 3.913597851562502\n",
      " batch 510 4.070246679687503\n",
      " batch 520 4.167059375000004\n",
      " batch 530 4.262803125000004\n",
      " batch 540 4.386807812500003\n",
      " batch 550 4.508426562500002\n",
      " batch 560 4.644603710937501\n",
      " batch 570 4.760343359375\n",
      " batch 580 4.858845703124999\n",
      " batch 590 4.942617773437499\n",
      " batch 600 5.072869726562499\n",
      " batch 610 5.198050585937499\n",
      " batch 620 5.310844140624998\n",
      " batch 630 5.407498242187499\n",
      " batch 640 5.515691015624998\n",
      " batch 650 5.642002734374997\n",
      " batch 660 5.737843554687497\n",
      " batch 670 5.836417382812496\n",
      " batch 680 5.955291601562497\n",
      " batch 690 6.074513867187496\n",
      " batch 700 6.224731835937496\n",
      " batch 710 6.352710156249996\n",
      " batch 720 6.4949916015624956\n",
      " batch 730 6.600219726562494\n",
      " batch 740 6.738479101562494\n",
      " batch 750 6.859921093749994\n",
      " batch 760 7.024052929687493\n",
      " batch 770 7.104580468749993\n",
      " batch 780 7.232168359374993\n",
      " batch 790 7.371689257812493\n",
      " batch 800 7.503741992187493\n",
      " batch 810 7.620038867187494\n",
      " batch 820 7.772370703124996\n",
      " batch 830 7.905964062499997\n",
      " batch 840 8.040167187499998\n",
      " batch 850 8.191710937499998\n",
      " batch 860 8.3053765625\n",
      " batch 870 8.3960267578125\n",
      " batch 880 8.557069921874996\n",
      " batch 890 8.704797265624999\n",
      " batch 900 8.852377539062498\n",
      " batch 910 9.002709570312499\n",
      " batch 920 9.1114046875\n",
      " batch 930 9.2759412109375\n",
      " batch 940 9.441847851562502\n",
      " batch 950 9.593563085937502\n",
      " batch 960 9.7229560546875\n",
      " batch 970 9.84453828125\n",
      " batch 980 9.9954904296875\n",
      " batch 990 10.096091406250002\n",
      " batch 1000 10.205994531250001\n",
      " batch 1010 10.307549218750001\n",
      " batch 1020 10.4443388671875\n",
      " batch 1030 10.565883789062504\n",
      " batch 1040 10.721025195312503\n",
      " batch 1050 10.837130078125004\n",
      " batch 1060 10.991870312500003\n",
      " batch 1070 11.122127148437503\n",
      " batch 1080 11.210374804687504\n",
      " batch 1090 11.336031445312502\n",
      " batch 1100 11.470779101562501\n",
      " batch 1110 11.607276562500001\n",
      " batch 1120 11.795632617187499\n",
      " batch 1130 11.935525585937498\n",
      " batch 1140 12.075602734374998\n",
      " batch 1150 12.184158203124996\n",
      " batch 1160 12.336908203124995\n",
      " batch 1170 12.531221484374994\n",
      " batch 1180 12.688882812499994\n",
      " batch 1190 12.846175585937495\n",
      " batch 1200 13.034980859374992\n",
      " batch 1210 13.181186718749991\n",
      " batch 1220 13.347190039062491\n",
      " batch 1230 13.475396484374992\n",
      " batch 1240 13.586039062499992\n",
      " batch 1250 13.727291796874992\n",
      " batch 1260 13.902567382812494\n",
      " batch 1270 14.008954296874993\n",
      " batch 1280 14.112556054687493\n",
      " batch 1290 14.240783789062494\n",
      " batch 1300 14.390010156249996\n",
      " batch 1310 14.539717968749997\n",
      " batch 1320 14.679396289062497\n",
      " batch 1330 14.847975781249998\n",
      " batch 1340 14.964343164062498\n",
      " batch 1350 15.083364843749996\n",
      " batch 1360 15.239239453124997\n",
      " batch 1370 15.365093359374997\n",
      " batch 1380 15.529631249999996\n",
      " batch 1390 15.698330078124995\n",
      " batch 1400 15.839442578124995\n",
      " batch 1410 15.985324023437494\n",
      " batch 1420 16.14527109375\n",
      " batch 1430 16.260593749999995\n",
      " batch 1440 16.3833236328125\n",
      " batch 1450 16.5524390625\n",
      " batch 1460 16.6865662109375\n",
      " batch 1470 16.839712499999997\n",
      " batch 1480 17.014027539062496\n",
      " batch 1490 17.191416210937497\n",
      " batch 1500 17.313075781250003\n",
      " batch 1510 17.404682421875\n",
      " batch 1520 17.5847130859375\n",
      " batch 1530 17.711240234374998\n",
      " batch 1540 17.891581445312493\n",
      " batch 1550 18.01720234374999\n",
      " batch 1560 18.166691406249992\n",
      " batch 1570 18.278117382812496\n",
      " batch 1580 18.400814648437493\n",
      " batch 1590 18.57523398437499\n",
      " batch 1600 18.729281835937496\n",
      " batch 1610 18.836808007812493\n",
      " batch 1620 18.952054296874994\n",
      " batch 1630 19.108765624999993\n",
      " batch 1640 19.229701757812492\n",
      " batch 1650 19.398062304687485\n",
      " batch 1660 19.51444335937498\n",
      " batch 1670 19.648652343749976\n",
      " batch 1680 19.80395957031248\n",
      " batch 1690 19.91069941406248\n",
      " batch 1700 20.040595117187486\n",
      " batch 1710 20.152562109374987\n",
      " batch 1720 20.31181425781249\n",
      " batch 1730 20.488615429687492\n",
      " batch 1740 20.647442968749992\n",
      " batch 1750 20.771298242187488\n",
      " batch 1760 20.917137304687486\n",
      " batch 1770 21.06194062499998\n",
      " batch 1780 21.231582031249978\n",
      " batch 1790 21.35667011718748\n",
      " batch 1800 21.522411132812483\n",
      " batch 1810 21.674545703124984\n",
      " batch 1820 21.80873320312498\n",
      " batch 1830 21.94373457031248\n",
      " batch 1840 22.03424550781249\n",
      " batch 1850 22.177969140624988\n",
      " batch 1860 22.37078281249999\n",
      " batch 1870 22.610609765624993\n",
      " batch 1880 22.744820312499993\n",
      " batch 1890 22.891905273437494\n",
      " batch 1900 23.046210546875\n",
      " batch 1910 23.2001248046875\n",
      " batch 1920 23.367917968750003\n",
      " batch 1930 23.5276560546875\n",
      " batch 1940 23.6143142578125\n",
      " batch 1950 23.744971093750003\n",
      " batch 1960 23.903273828125\n",
      " batch 1970 24.018836523437496\n",
      " batch 1980 24.1492310546875\n",
      " batch 1990 24.35029121093751\n",
      " batch 2000 24.495849609375014\n",
      " batch 2010 24.611191210937513\n",
      " batch 2020 24.730352148437518\n",
      " batch 2030 24.847389648437517\n",
      " batch 2040 24.999152343750016\n",
      " batch 2050 25.139455859375015\n",
      " batch 2060 25.30388359375001\n",
      " batch 2070 25.45920078125001\n",
      " batch 2080 25.61198320312501\n",
      " batch 2090 25.82816113281251\n",
      " batch 2100 25.97766562500001\n",
      " batch 2110 26.11623125000001\n",
      " batch 2120 26.294410156250002\n",
      " batch 2130 26.400755078125\n",
      " batch 2140 26.547393164062505\n",
      " batch 2150 26.719416015625\n",
      " batch 2160 26.911734570312507\n",
      " batch 2170 27.04719843750001\n",
      " batch 2180 27.19715332031251\n",
      " batch 2190 27.338634570312514\n",
      " batch 2200 27.503218164062513\n",
      " batch 2210 27.66524921875002\n",
      " batch 2220 27.779692578125015\n",
      " batch 2230 27.934795312500015\n",
      " batch 2240 28.082503906250018\n",
      " batch 2250 28.206018750000016\n",
      " batch 2260 28.380577929687515\n",
      " batch 2270 28.518167578125013\n",
      " batch 2280 28.639897851562512\n",
      " batch 2290 28.791855273437513\n",
      " batch 2300 28.91097910156251\n",
      " batch 2310 29.090315820312515\n",
      " batch 2320 29.220705664062518\n",
      " batch 2330 29.377165625000018\n",
      " batch 2340 29.55893398437502\n",
      " batch 2350 29.69112460937502\n",
      " batch 2360 29.84530488281252\n",
      " batch 2370 30.06207246093753\n",
      " batch 2380 30.191469921875026\n",
      " batch 2390 30.328786523437525\n",
      " batch 2400 30.49655097656252\n",
      " batch 2410 30.622305468750024\n",
      " batch 2420 30.750101757812523\n",
      " batch 2430 30.920302539062526\n",
      " batch 2440 31.05796132812502\n",
      " batch 2450 31.258836132812515\n",
      " batch 2460 31.438212304687518\n",
      " batch 2470 31.53722187500002\n",
      " batch 2480 31.633647851562518\n",
      " batch 2490 31.802637109375016\n",
      " batch 2500 31.93454628906252\n",
      " batch 2510 32.06048417968751\n",
      " batch 2520 32.18662207031251\n",
      " batch 2530 32.36426328124999\n",
      " batch 2540 32.48930566406249\n",
      " batch 2550 32.710305078124996\n",
      " batch 2560 32.8286427734375\n",
      " batch 2570 32.98681132812499\n",
      " batch 2580 33.1321755859375\n",
      " batch 2590 33.2721572265625\n",
      " batch 2600 33.45990136718749\n",
      " batch 2610 33.621120703125\n",
      " batch 2620 33.78163808593749\n",
      " batch 2630 33.88723984374998\n",
      " batch 2640 34.04525820312499\n",
      " batch 2650 34.23150605468748\n",
      " batch 2660 34.405728515624986\n",
      " batch 2670 34.53592031249999\n",
      " batch 2680 34.67834863281249\n",
      " batch 2690 34.82796777343749\n",
      " batch 2700 34.944675390624994\n",
      " batch 2710 35.10098554687499\n",
      " batch 2720 35.26502832031249\n",
      " batch 2730 35.37602851562498\n",
      " batch 2740 35.531649023437474\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " batch 2750 35.702688085937474\n",
      " batch 2760 35.89021542968747\n",
      " batch 2770 36.03893867187497\n",
      " batch 2780 36.16528300781246\n",
      " batch 2790 36.30068554687497\n",
      " batch 2800 36.45427207031249\n",
      " batch 2810 36.585259570312495\n",
      " batch 2820 36.741649023437496\n",
      " batch 2830 36.9541619140625\n",
      " batch 2840 37.1263392578125\n",
      " batch 2850 37.273319140625006\n",
      " batch 2860 37.42782519531251\n",
      " batch 2870 37.5863970703125\n",
      " batch 2880 37.733478125\n",
      " batch 2890 37.82072246093749\n",
      " batch 2900 37.99586835937498\n",
      " batch 2910 38.17503183593748\n",
      " batch 2920 38.36104589843749\n",
      " batch 2930 38.504339648437494\n",
      " batch 2940 38.68731621093749\n",
      " batch 2950 38.857885156249985\n",
      " batch 2960 39.03303300781248\n",
      " batch 2970 39.209511914062475\n",
      " batch 2980 39.35282617187497\n",
      " batch 2990 39.56351562499997\n",
      " batch 3000 39.72957148437498\n",
      " batch 3010 39.88578652343749\n",
      " batch 3020 40.04232499999999\n",
      " batch 3030 40.210052539062495\n",
      " batch 3040 40.338597656249995\n",
      " batch 3050 40.4884521484375\n",
      " batch 3060 40.6512140625\n",
      " batch 3070 40.792176757812506\n",
      " batch 3080 40.962842382812504\n",
      " batch 3090 41.120462890625\n",
      " batch 3100 41.246116406249996\n",
      " batch 3110 41.3730884765625\n",
      " batch 3120 41.48702109375\n",
      " batch 3130 41.63307714843751\n",
      " batch 3140 41.786540429687506\n",
      " batch 3150 41.909140625\n",
      " batch 3160 42.082445703125\n",
      " batch 3170 42.214776171875\n",
      " batch 3180 42.378893945312505\n",
      " batch 3190 42.5845763671875\n",
      " batch 3200 42.69015078125001\n",
      " batch 3210 42.82306035156251\n",
      " batch 3220 42.947884179687506\n",
      " batch 3230 43.0902455078125\n",
      " batch 3240 43.24380937500001\n",
      " batch 3250 43.41677695312501\n",
      " batch 3260 43.55154140625001\n",
      " batch 3270 43.6643232421875\n",
      " batch 3280 43.8280630859375\n",
      " batch 3290 43.98578261718751\n",
      " batch 3300 44.1056546875\n",
      " batch 3310 44.289907421875\n",
      " batch 3320 44.442033203125\n",
      " batch 3330 44.6240841796875\n",
      " batch 3340 44.79888378906251\n",
      " batch 3350 44.91309785156251\n",
      " batch 3360 45.098264062500014\n",
      " batch 3370 45.20513984375001\n",
      " batch 3380 45.37138300781252\n",
      " batch 3390 45.47165839843751\n",
      " batch 3400 45.61655117187502\n",
      " batch 3410 45.793004687500016\n",
      " batch 3420 45.95147285156252\n",
      " batch 3430 46.087166796875024\n",
      " batch 3440 46.22622148437503\n",
      " batch 3450 46.34713593750003\n",
      " batch 3460 46.466091992187536\n",
      " batch 3470 46.641033593750045\n",
      " batch 3480 46.77642031250004\n",
      " batch 3490 46.948926367187546\n",
      " batch 3500 47.11727636718755\n",
      " batch 3510 47.29791562500005\n",
      " batch 3520 47.406351171875045\n",
      " batch 3530 47.543115039062535\n",
      " batch 3540 47.71141718750002\n",
      " batch 3550 47.868471875000026\n",
      " batch 3560 48.025027148437516\n",
      " batch 3570 48.19684941406252\n",
      " batch 3580 48.35077031250002\n",
      " batch 3590 48.49427050781251\n",
      " batch 3600 48.67177167968751\n",
      " batch 3610 48.85263535156252\n",
      " batch 3620 49.014233398437526\n",
      " batch 3630 49.18755722656252\n",
      " batch 3640 49.335793750000015\n",
      " batch 3650 49.45348867187503\n",
      " batch 3660 49.61967324218752\n",
      " batch 3670 49.753723632812516\n",
      " batch 3680 49.86911718750001\n",
      " batch 3690 49.990750195312515\n",
      " batch 3700 50.16833164062501\n",
      " batch 3710 50.304416992187505\n",
      " batch 3720 50.52170195312501\n",
      " batch 3730 50.72807187500001\n",
      " batch 3740 50.88261914062501\n",
      " batch 3750 51.01594394531251\n",
      " batch 3760 51.12019453125\n",
      " batch 3770 51.2562005859375\n",
      " batch 3780 51.42753281249999\n",
      " batch 3790 51.55570820312499\n",
      " batch 3800 51.69977207031249\n",
      " batch 3810 51.86035117187498\n",
      " batch 3820 51.99414199218748\n",
      " batch 3830 52.15982734374997\n",
      " batch 3840 52.29192304687497\n",
      " batch 3850 52.415736523437474\n",
      " batch 3860 52.588980664062476\n",
      " batch 3870 52.74119003906249\n",
      " batch 3880 52.89198320312499\n",
      " batch 3890 52.98322949218748\n",
      " batch 3900 53.038723828124986\n",
      " batch 3910 53.07993339843749\n",
      " batch 3920 53.124829492187494\n",
      " batch 3930 53.167043945312486\n",
      " batch 3940 53.201063476562474\n",
      " batch 3950 53.23322656249998\n",
      " batch 3960 53.265470117187476\n",
      " batch 3970 53.300332226562475\n",
      " batch 3980 53.33561230468748\n",
      " batch 3990 53.37460585937497\n",
      " batch 4000 53.404711718749965\n",
      " batch 4010 53.43458867187496\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [41]\u001b[0m, in \u001b[0;36m<cell line: 10>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m train loss \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrain_loss\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m  val loss \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mval_loss\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)        \n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m---> 38\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m tbi, data \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(train_dataloader):\n\u001b[1;32m     39\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m tbi \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m10\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     40\u001b[0m             \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m batch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtbi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrain_loss\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/recommendations/lib/python3.10/site-packages/torch/utils/data/dataloader.py:681\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    678\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    679\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    680\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 681\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    682\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    683\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    684\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    685\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/anaconda3/envs/recommendations/lib/python3.10/site-packages/torch/utils/data/dataloader.py:721\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    719\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    720\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 721\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    722\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    723\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/anaconda3/envs/recommendations/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:49\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfetch\u001b[39m(\u001b[38;5;28mself\u001b[39m, possibly_batched_index):\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_collation:\n\u001b[0;32m---> 49\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/anaconda3/envs/recommendations/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:49\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfetch\u001b[39m(\u001b[38;5;28mself\u001b[39m, possibly_batched_index):\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_collation:\n\u001b[0;32m---> 49\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "Input \u001b[0;32mIn [35]\u001b[0m, in \u001b[0;36mCustomDataset.__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, index):\n\u001b[0;32m----> 6\u001b[0m     row \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataframe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mto_numpy()\n\u001b[1;32m      7\u001b[0m     userid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(row[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m      8\u001b[0m     movieid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(row[\u001b[38;5;241m1\u001b[39m])\n",
      "File \u001b[0;32m~/anaconda3/envs/recommendations/lib/python3.10/site-packages/pandas/core/indexing.py:967\u001b[0m, in \u001b[0;36m_LocationIndexer.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    964\u001b[0m axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxis \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    966\u001b[0m maybe_callable \u001b[38;5;241m=\u001b[39m com\u001b[38;5;241m.\u001b[39mapply_if_callable(key, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj)\n\u001b[0;32m--> 967\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmaybe_callable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/recommendations/lib/python3.10/site-packages/pandas/core/indexing.py:1513\u001b[0m, in \u001b[0;36m_iLocIndexer._getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1510\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getbool_axis(key, axis\u001b[38;5;241m=\u001b[39maxis)\n\u001b[1;32m   1512\u001b[0m \u001b[38;5;66;03m# a list of integers\u001b[39;00m\n\u001b[0;32m-> 1513\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[43mis_list_like_indexer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m   1514\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_list_axis(key, axis\u001b[38;5;241m=\u001b[39maxis)\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# a single integer\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/recommendations/lib/python3.10/site-packages/pandas/core/indexers/utils.py:69\u001b[0m, in \u001b[0;36mis_list_like_indexer\u001b[0;34m(key)\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m val \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m is_integer(val)\n\u001b[1;32m     62\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[1;32m     63\u001b[0m         is_int_or_none(slc\u001b[38;5;241m.\u001b[39mstart)\n\u001b[1;32m     64\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m is_int_or_none(slc\u001b[38;5;241m.\u001b[39mstop)\n\u001b[1;32m     65\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m is_int_or_none(slc\u001b[38;5;241m.\u001b[39mstep)\n\u001b[1;32m     66\u001b[0m     )\n\u001b[0;32m---> 69\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mis_list_like_indexer\u001b[39m(key) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n\u001b[1;32m     70\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;124;03m    Check if we have a list-like indexer that is *not* a NamedTuple.\u001b[39;00m\n\u001b[1;32m     72\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[38;5;124;03m    bool\u001b[39;00m\n\u001b[1;32m     80\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m     81\u001b[0m     \u001b[38;5;66;03m# allow a list_like, but exclude NamedTuples which can be indexers\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# training\n",
    "epochs=4\n",
    "lr=0.01\n",
    "wd=0.0\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=wd)\n",
    "#model.to(device)\n",
    "#optimizer.to(device)\n",
    "#train_dataloader.to(device)\n",
    "model.train()\n",
    "for ei in range(epochs):\n",
    "    print(f\" epoch {ei}\")\n",
    "    train_loss = 0.0\n",
    "    val_loss = 0.0\n",
    "    if False:\n",
    "        #print(df.userId.nunique(), df.movieId.nunique())\n",
    "        \n",
    "        userIds = torch.LongTensor(traindf.userId.values).cuda()\n",
    "        movieIds = torch.LongTensor(traindf.movieId.values).cuda()\n",
    "        ratings = torch.FloatTensor(traindf.rating.values).cuda()\n",
    "        print(userIds.max(), userIds.shape, movieIds.max())\n",
    "        y_hat = model(userIds, movieIds)\n",
    "        loss = F.mse_loss(y_hat, ratings)\n",
    "        train_loss += np.round(loss.item(), 4)/ userIds.size[0]\n",
    "        optimizer.zero_grad()  # reset gradient\n",
    "        loss.backward()\n",
    "        optimizer.step() \n",
    "        \n",
    "        # validation\n",
    "        userIds = torch.LongTensor(valdf.userId.values).cuda()\n",
    "        movieIds = torch.LongTensor(valdf.movieId.values).cuda()\n",
    "        ratings = torch.FloatTensor(valdf.rating.values).cuda()\n",
    "        y_hat = model(users, movies)\n",
    "        loss = F.mse_loss(y_hat, ratings)\n",
    "        val_loss += np.round(loss.item(), 4)/ userIds.size()[0]        \n",
    "\n",
    "        print(f\" train loss {train_loss}  val loss {val_loss}\")        \n",
    "    if True:\n",
    "        for tbi, data in enumerate(train_dataloader):\n",
    "            if tbi % 10 == 0:\n",
    "                print(f\" batch {tbi} {train_loss}\")\n",
    "            users, movies, ratings = data\n",
    "            users = users.cuda()\n",
    "            movies = movies.cuda()\n",
    "            ratings = ratings.cuda()\n",
    "            y_hat = model(users, movies)\n",
    "            loss = F.mse_loss(y_hat, ratings)\n",
    "            train_loss += np.round(loss.item(), 4)/ users.size()[0]\n",
    "\n",
    "            optimizer.zero_grad()  # reset gradient\n",
    "            loss.backward()\n",
    "            optimizer.step() \n",
    "\n",
    "        print(f\"train_loss {train_loss}\")\n",
    "        for tbi, data in enumerate(val_dataloader):\n",
    "            if tbi+1 % 128 == 0:\n",
    "                print(f\" val batch {tbi} {val_loss}\")\n",
    "            for i, data in enumerate(val_dataloader):\n",
    "                users, movies, ratings = data\n",
    "                users = users.cuda()\n",
    "                movies = movies.cuda()\n",
    "                ratings = ratings.cuda()\n",
    "                y_hat = model(users, movies)\n",
    "                loss = F.mse_loss(y_hat, ratings)\n",
    "                val_loss += np.round(loss.item(), 4)/ users.size()[0]\n",
    "        print(\"val_loss {val_loss}\")        \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "83ffe10c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Tensor"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a127ef5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d497e908",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40ba10f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddf472ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ee4a39d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8691cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(users)\n",
    "print(users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d639d1a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, df):\n",
    "    model.eval()\n",
    "    users = torch.LongTensor(df.userId.values)\n",
    "    movies = torch.LongTensor(df.movieId.values)\n",
    "    ratings = torch.FloatTensor(df.rating.values)\n",
    "    y_hat = model(users, movies)\n",
    "    loss = F.mse_loss(y_hat, ratings)\n",
    "    return  loss.item()\n",
    "val_err = test_model(model, val)\n",
    "test_err = test_model(model, test)    \n",
    "print(val_err, test_err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b3f70e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "user = torch.tensor([10])\n",
    "games = torch.tensor(game_ratings['movieId'].unique().tolist())\n",
    "predictions = model(user, games).tolist()\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a985a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_predictions = [i/max(predictions)*10 for i in predictions]\n",
    "print(normalized_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8318c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sortedIndices = predictions.argsort()\n",
    "recommendations = dataset['Title'].unique()[sortedIndices][:30]  # taking top 30\n",
    "print(recommendations)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "recommendations",
   "language": "python",
   "name": "recommendations"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

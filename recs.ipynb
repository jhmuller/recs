{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "537bd595",
   "metadata": {},
   "source": [
    "https://betterprogramming.pub/building-a-recommendation-engine-with-pytorch-d64be4856fe7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efc9817a",
   "metadata": {},
   "source": [
    "# Embeddings for Recommendations\n",
    "\n",
    "Here I use a move rating data set from Kaggle.\n",
    "In this notebook I will derive embeddings for users and movies\n",
    "and these will be the ingredients of a matrix factorization\n",
    "of the full rating matrix.\n",
    "\n",
    "We will train a simple Neural Net using Pytorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "b2313637",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch.cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "d89d633f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "9fb9dffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "!export CUDA_LAUNCH_BLOCKING=1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "002f08c1",
   "metadata": {},
   "source": [
    "### Note: I am going to use my GPU card ... or try to anyway."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9c1a4b36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device in use: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"Device in use:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e216cfa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Read in the data and show shape and head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "6996373a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(26024289, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>110</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1425941529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>147</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1425942435</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  movieId  rating   timestamp\n",
       "0       1      110     1.0  1425941529\n",
       "1       1      147     4.5  1425942435"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"ratings.csv\")\n",
    "print(df.shape)\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "c33f3eb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max userId 270896 num users 270896\n",
      "max movieId 176275 num movies 45115\n"
     ]
    }
   ],
   "source": [
    "print(f\"max userId {df.userId.max()} num users {df.userId.nunique()}\")\n",
    "print(f\"max movieId {df.movieId.max()} num movies {df.movieId.nunique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "398b54ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max userId 9999 num users 9930\n",
      "max movieId 4999 num movies 4783\n",
      "(676352, 4)\n"
     ]
    }
   ],
   "source": [
    "subsample = True\n",
    "if subsample:\n",
    "    max_user = 10000\n",
    "    max_movie = 5000\n",
    "    df = df.loc[df.movieId < max_movie]\n",
    "    df = df.loc[df.userId < max_user]\n",
    "    print(f\"max userId {df.userId.max()} num users {df.userId.nunique()}\")\n",
    "    print(f\"max movieId {df.movieId.max()} num movies {df.movieId.nunique()}\")    \n",
    "    print(df.shape)    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b978048f",
   "metadata": {},
   "source": [
    "## Partition the dataset\n",
    "into train, val and test.\n",
    "We can use val to tune the hyper parameters.\n",
    "\n",
    "Test will be held out until all training is done.\n",
    "\n",
    "We could use the sklearn function but I find this just as easy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "f1aac548",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60871, 4) (547846, 4)\n"
     ]
    }
   ],
   "source": [
    "def partition(df, pct=0.1):\n",
    "    size = int(np.floor(df.shape[0])*0.1)\n",
    "    idx = list(np.random.choice(df.index, size, replace=False))\n",
    "    subset = df.filter(items=idx, axis=0)\n",
    "    rest = df.drop(index = idx)\n",
    "    return subset, rest\n",
    "\n",
    "testdf, val_train = partition(df, 0.1)\n",
    "valdf, traindf = partition(val_train, 0.2)\n",
    "traindf.shape[0] / 1024\n",
    "print(valdf.shape, traindf.shape)\n",
    "traindf.reset_index(inplace=True)\n",
    "valdf.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8e14b13",
   "metadata": {},
   "source": [
    "## the Model\n",
    "The model is fairly simple: 2 embedding layers, \n",
    "    one each for users and movies.\n",
    "    \n",
    "At the end of \"froward\" we simply do the dot product."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "d4e8e124",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MF(nn.Module):\n",
    "    def __init__(self, n_users, n_movies, emb_size=100):\n",
    "        super(MF, self).__init__()\n",
    "        self.n_users = n_users\n",
    "        self.n_movies = n_movies\n",
    "        print(f\" n_users: {n_users}  n_movies: {n_movies}\")\n",
    "        self.user_emb = nn.Embedding(n_users, emb_size)\n",
    "        self.movie_emb = nn.Embedding(n_movies, emb_size)\n",
    "        \n",
    "        # initializing our matrices with a positive number generally will yield better results\n",
    "        self.user_emb.weight.data.uniform_(0, 0.5)\n",
    "        self.movie_emb.weight.data.uniform_(0, 0.5)\n",
    "    \n",
    "    def forward(self, users, movies):\n",
    "        m = self.movie_emb(movies)\n",
    "        u = self.user_emb(users)\n",
    "        return (u * m).sum(1)  # taking the dot product\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99c0ff82",
   "metadata": {},
   "source": [
    "## instantiate the Model\n",
    "and push it to the gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaacc2e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "2ec19318",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000 5000\n",
      " n_users: 10000  n_movies: 5000\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "USE_CUDA = False\n",
    "n_users = df.userId.max()+1\n",
    "n_movies = df.movieId.max()+1\n",
    "emb_size = 64\n",
    "print(n_users, n_movies)\n",
    "model = MF(n_users=n_users, n_movies=n_movies, emb_size=emb_size)\n",
    "use_cuda = False\n",
    "if USE_CUDA:\n",
    "    if torch.cuda.is_available():\n",
    "        print(\"using cuda\")\n",
    "        model = model.to(device)\n",
    "print(next(model.parameters()).is_cuda)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3f59253",
   "metadata": {},
   "source": [
    "## Dataset and dataloader\n",
    "I want to use mini-batch training so we need a dataset\n",
    "and a dataloader.\n",
    "\n",
    "I adapted some code for converting a pandas dataframe into a dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "1a3e05a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " len 547846\n",
      " len 60871\n"
     ]
    }
   ],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, dataframe):\n",
    "        self.dataframe = dataframe\n",
    "        print(f\" len {dataframe.shape[0]}\")\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        #print(index)\n",
    "        #row = self.dataframe.iloc[index].to_numpy()\n",
    "        userid = self.dataframe.userId[index]\n",
    "        movieid = self.dataframe.movieId[index]   #int(row[1])\n",
    "        rating = np.float32(self.dataframe.rating[index])    #np.float32(row[2])\n",
    "        return userid, movieid, rating\n",
    "\n",
    "    def __len__(self):\n",
    "        length = self.dataframe.shape[0]\n",
    "        return length\n",
    "\n",
    "traindata = CustomDataset(dataframe=traindf)\n",
    "train_dataloader = DataLoader(traindata, batch_size=256)\n",
    "\n",
    "valdata = CustomDataset(dataframe=valdf)\n",
    "val_dataloader = DataLoader(valdata, batch_size=256) # pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "2196c2a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " epoch 0  2022-10-04 16:42:48.485239\n",
      " val batch 0 0.0\n",
      " val batch 20 187.71937192740606\n",
      " val batch 40 375.4387438548118\n",
      " val batch 60 563.1581157822172\n",
      " val batch 80 750.8774877096228\n",
      " val batch 100 938.5968596370283\n",
      " val batch 120 1126.3162315644338\n",
      " val batch 140 1314.0356034918393\n",
      " val batch 160 1501.7549754192448\n",
      " val batch 180 1689.4743473466503\n",
      " val batch 200 1877.1937192740559\n",
      " val batch 220 2064.9130912014616\n",
      "val_loss 2233.8605  2022-10-04 16:47:30.599059\n",
      " batch 0 0.0\n",
      " batch 150 1.31846070359461\n",
      " batch 300 2.370537465903908\n",
      " batch 450 3.3947003493085504\n",
      " batch 600 4.506368232192472\n",
      " batch 750 6.0191912818700075\n",
      " batch 900 7.619078364688903\n",
      " batch 1050 9.041840915568173\n",
      " batch 1200 10.571063495939597\n",
      " batch 1350 11.945449589984491\n",
      " batch 1500 13.334848600905389\n",
      " batch 1650 14.685705098789185\n",
      " batch 1800 16.15197489899583\n",
      " batch 1950 18.501841221703216\n",
      " batch 2100 20.556309435749426\n",
      "train_loss 21.1106 2022-10-04 16:47:54.881264\n",
      " val batch 0 2233.8605259361266\n",
      " val batch 20 2397.8081979301733\n",
      " val batch 40 2561.75586992422\n",
      " val batch 60 2725.7035419182666\n",
      " val batch 80 2889.6512139123133\n",
      " val batch 100 3053.59888590636\n",
      " val batch 120 3217.5465579004067\n",
      " val batch 140 3381.4942298944534\n",
      " val batch 160 3545.4419018885\n",
      " val batch 180 3709.3895738825468\n",
      " val batch 200 3873.3372458765934\n",
      " val batch 220 4037.28491787064\n",
      "val_loss 4184.8378  2022-10-04 16:52:38.205140\n",
      " epoch 1  2022-10-04 16:52:38.205186\n",
      " val batch 0 0.0\n",
      " val batch 20 163.9476719940427\n",
      " val batch 40 327.8953439880857\n",
      " val batch 60 491.843015982129\n",
      " val batch 80 655.7906879761713\n",
      " val batch 100 819.7383599702134\n",
      " val batch 120 983.6860319642556\n",
      " val batch 140 1147.6337039582977\n",
      " val batch 160 1311.5813759523398\n",
      " val batch 180 1475.529047946382\n",
      " val batch 200 1639.4767199404241\n",
      " val batch 220 1803.4243919344663\n",
      "val_loss 1950.9773  2022-10-04 16:57:21.505613\n",
      " batch 0 0.0\n",
      " batch 150 1.1071650851517916\n",
      " batch 300 2.115387615049258\n",
      " batch 450 3.324738500872627\n",
      " batch 600 4.585665190825239\n",
      " batch 750 6.046036054147407\n",
      " batch 900 7.741994124371558\n",
      " batch 1050 9.53610159130767\n",
      " batch 1200 11.406110229436308\n",
      " batch 1350 13.145099381916225\n",
      " batch 1500 14.870434472337365\n",
      " batch 1650 16.631517156027257\n",
      " batch 1800 18.37996415561065\n",
      " batch 1950 20.100503569003195\n",
      " batch 2100 21.710115110268816\n",
      "train_loss 22.9114 2022-10-04 16:57:46.270007\n",
      " val batch 0 1950.9772967291042\n",
      " val batch 20 2148.0422195397546\n",
      " val batch 40 2345.107142350405\n",
      " val batch 60 2542.1720651610553\n",
      " val batch 80 2739.2369879717057\n",
      " val batch 100 2936.301910782356\n",
      " val batch 120 3133.3668335930065\n",
      " val batch 140 3330.431756403657\n",
      " val batch 160 3527.4966792143073\n",
      " val batch 180 3724.5616020249577\n",
      " val batch 200 3921.626524835608\n",
      " val batch 220 4118.691447646257\n",
      "val_loss 4296.0499  2022-10-04 17:02:31.188993\n",
      " epoch 2  2022-10-04 17:02:31.189041\n",
      " val batch 0 0.0\n",
      " val batch 20 197.06492281064922\n",
      " val batch 40 394.12984562129844\n",
      " val batch 60 591.1947684319472\n",
      " val batch 80 788.2596912425953\n",
      " val batch 100 985.3246140532434\n",
      " val batch 120 1182.3895368638935\n",
      " val batch 140 1379.4544596745438\n",
      " val batch 160 1576.5193824851942\n",
      " val batch 180 1773.5843052958446\n",
      " val batch 200 1970.649228106495\n",
      " val batch 220 2167.7141509171456\n",
      "val_loss 2345.0726  2022-10-04 17:07:12.641339\n",
      " batch 0 0.0\n",
      " batch 150 1.6035769248846918\n",
      " batch 300 3.3270148758310825\n",
      " batch 450 4.850536165526137\n",
      " batch 600 6.333406888414174\n",
      " batch 750 7.750032044015825\n",
      " batch 900 9.301465064752847\n",
      " batch 1050 10.980763837695122\n",
      " batch 1200 12.697248939424753\n",
      " batch 1350 14.560892110690475\n",
      " batch 1500 16.333201680798084\n",
      " batch 1650 18.12494928855449\n",
      " batch 1800 20.12707250425592\n",
      " batch 1950 22.100677102804184\n",
      " batch 2100 23.880954819265753\n",
      "train_loss 24.8447 2022-10-04 17:07:37.169996\n",
      " val batch 0 2345.072581446731\n",
      " val batch 20 2499.8034818748706\n",
      " val batch 40 2654.5343823030103\n",
      " val batch 60 2809.26528273115\n",
      " val batch 80 2963.9961831592896\n",
      " val batch 100 3118.727083587429\n",
      " val batch 120 3273.457984015569\n",
      " val batch 140 3428.1888844437085\n",
      " val batch 160 3582.919784871848\n",
      " val batch 180 3737.650685299988\n",
      " val batch 200 3892.3815857281274\n",
      " val batch 220 4047.112486156267\n",
      "val_loss 4186.3703  2022-10-04 17:12:18.372011\n",
      " epoch 3  2022-10-04 17:12:18.372058\n",
      " val batch 0 0.0\n",
      " val batch 20 154.73090042814084\n",
      " val batch 40 309.4618008562816\n",
      " val batch 60 464.1927012844224\n",
      " val batch 80 618.923601712564\n",
      " val batch 100 773.654502140706\n",
      " val batch 120 928.3854025688479\n",
      " val batch 140 1083.116302996989\n",
      " val batch 160 1237.8472034251286\n",
      " val batch 180 1392.5781038532682\n",
      " val batch 200 1547.3090042814079\n",
      " val batch 220 1702.0399047095475\n",
      "val_loss 1841.2977  2022-10-04 17:17:00.781543\n",
      " batch 0 0.0\n",
      " batch 150 1.5703612761572003\n",
      " batch 300 3.162211308721453\n",
      " batch 450 5.172059228178114\n",
      " batch 600 6.835970928426832\n",
      " batch 750 8.399850981775671\n",
      " batch 900 9.886199253611267\n",
      " batch 1050 11.422483279369771\n",
      " batch 1200 13.01125622401014\n",
      " batch 1350 14.632172513753176\n",
      " batch 1500 16.181614936795086\n",
      " batch 1650 17.675235798116773\n",
      " batch 1800 19.173333615995944\n",
      " batch 1950 20.95191446458921\n",
      " batch 2100 22.67075913446024\n",
      "train_loss 23.5998 2022-10-04 17:17:25.521903\n",
      " val batch 0 1841.2977150948732\n",
      " val batch 20 2006.6135446775374\n",
      " val batch 40 2171.929374260198\n",
      " val batch 60 2337.245203842858\n",
      " val batch 80 2502.5610334255175\n",
      " val batch 100 2667.876863008177\n",
      " val batch 120 2833.192692590837\n",
      " val batch 140 2998.5085221734967\n",
      " val batch 160 3163.8243517561564\n",
      " val batch 180 3329.140181338816\n",
      " val batch 200 3494.456010921476\n",
      " val batch 220 3659.7718405041355\n",
      "val_loss 3808.5561  2022-10-04 17:22:08.147336\n"
     ]
    }
   ],
   "source": [
    "# training\n",
    "epochs=4\n",
    "lr=0.01\n",
    "wd=0.0\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=wd)\n",
    "#model.to(device)\n",
    "#optimizer.to(device)\n",
    "#train_dataloader.to(device)\n",
    "model.train()\n",
    "for ei in range(epochs):\n",
    "    print(f\" epoch {ei}  {datetime.datetime.now()}\")\n",
    "    train_loss = 0.0\n",
    "    val_loss = 0.0\n",
    "    if False:\n",
    "        #print(df.userId.nunique(), df.movieId.nunique())\n",
    "        \n",
    "        userIds = torch.LongTensor(traindf.userId.values).cuda()\n",
    "        movieIds = torch.LongTensor(traindf.movieId.values).cuda()\n",
    "        ratings = torch.FloatTensor(traindf.rating.values).cuda()\n",
    "        print(userIds.max(), userIds.shape, movieIds.max())\n",
    "        y_hat = model(userIds, movieIds)\n",
    "        loss = F.mse_loss(y_hat, ratings)\n",
    "        train_loss += np.round(loss.item(), 4)/ userIds.size[0]\n",
    "        optimizer.zero_grad()  # reset gradient\n",
    "        loss.backward()\n",
    "        optimizer.step() \n",
    "        \n",
    "        # validation\n",
    "        userIds = torch.LongTensor(valdf.userId.values).cuda()\n",
    "        movieIds = torch.LongTensor(valdf.movieId.values).cuda()\n",
    "        ratings = torch.FloatTensor(valdf.rating.values).cuda()\n",
    "        y_hat = model(users, movies)\n",
    "        loss = F.mse_loss(y_hat, ratings)\n",
    "        val_loss += np.round(loss.item(), 4)/ userIds.size()[0]        \n",
    "\n",
    "        print(f\" train loss {train_loss}  val loss {val_loss}\") \n",
    "    if True:\n",
    "        for tbi, data in enumerate(val_dataloader):\n",
    "            if tbi % 20 == 0:\n",
    "                pass\n",
    "                print(f\" val batch {tbi} {val_loss}\")\n",
    "            for i, data in enumerate(val_dataloader):\n",
    "                users, movies, ratings = data\n",
    "                users = users#.cuda()\n",
    "                movies = movies#.cuda()\n",
    "                ratings = ratings#.cuda()\n",
    "                y_hat = model(users, movies)\n",
    "                loss = F.mse_loss(y_hat, ratings)\n",
    "                val_loss += loss.item()/ users.size()[0]\n",
    "        print(f\"val_loss {np.round(val_loss, 4)}  {datetime.datetime.now()}\")          \n",
    "    if True:\n",
    "        for tbi, data in enumerate(train_dataloader):\n",
    "            if tbi % 150 == 0:\n",
    "                pass\n",
    "                print(f\" batch {tbi} {train_loss}\")\n",
    "            users, movies, ratings = data\n",
    "            users = users#.cuda()\n",
    "            movies = movies#.cuda()\n",
    "            ratings = ratings#.cuda()\n",
    "            y_hat = model(users, movies)\n",
    "            loss = F.mse_loss(y_hat, ratings)\n",
    "            train_loss += loss.item()/ users.size()[0]\n",
    "\n",
    "            optimizer.zero_grad()  # reset gradient\n",
    "            loss.backward()\n",
    "            optimizer.step() \n",
    "        print(f\"train_loss {np.round(train_loss, 4)} {datetime.datetime.now()}\")        \n",
    "    if True:\n",
    "        for tbi, data in enumerate(val_dataloader):\n",
    "            if tbi % 20 == 0:\n",
    "                pass\n",
    "                print(f\" val batch {tbi} {val_loss}\")\n",
    "            for i, data in enumerate(val_dataloader):\n",
    "                users, movies, ratings = data\n",
    "                users = users#.cuda()\n",
    "                movies = movies#.cuda()\n",
    "                ratings = ratings#.cuda()\n",
    "                y_hat = model(users, movies)\n",
    "                loss = F.mse_loss(y_hat, ratings)\n",
    "                val_loss += loss.item()/ users.size()[0]\n",
    "        print(f\"val_loss {np.round(val_loss, 4)}  {datetime.datetime.now()}\")          \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "d639d1a7",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'val' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [71]\u001b[0m, in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m     loss \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mmse_loss(y_hat, ratings)\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m  loss\u001b[38;5;241m.\u001b[39mitem()\n\u001b[0;32m----> 9\u001b[0m val_err \u001b[38;5;241m=\u001b[39m test_model(model, \u001b[43mval\u001b[49m)\n\u001b[1;32m     10\u001b[0m test_err \u001b[38;5;241m=\u001b[39m test_model(model, test)    \n\u001b[1;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(val_err, test_err)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'val' is not defined"
     ]
    }
   ],
   "source": [
    "def test_model(model, df):\n",
    "    model.eval()\n",
    "    users = torch.LongTensor(df.userId.values)\n",
    "    movies = torch.LongTensor(df.movieId.values)\n",
    "    ratings = torch.FloatTensor(df.rating.values)\n",
    "    y_hat = model(users, movies)\n",
    "    loss = F.mse_loss(y_hat, ratings)\n",
    "    return  loss.item()\n",
    "val_err = test_model(model, val)\n",
    "test_err = test_model(model, test)    \n",
    "print(val_err, test_err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b3f70e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "user = torch.tensor([10])\n",
    "games = torch.tensor(game_ratings['movieId'].unique().tolist())\n",
    "predictions = model(user, games).tolist()\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a985a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_predictions = [i/max(predictions)*10 for i in predictions]\n",
    "print(normalized_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8318c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sortedIndices = predictions.argsort()\n",
    "recommendations = dataset['Title'].unique()[sortedIndices][:30]  # taking top 30\n",
    "print(recommendations)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "recommendations",
   "language": "python",
   "name": "recommendations"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

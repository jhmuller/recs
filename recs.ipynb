{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "537bd595",
   "metadata": {},
   "source": [
    "https://betterprogramming.pub/building-a-recommendation-engine-with-pytorch-d64be4856fe7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efc9817a",
   "metadata": {},
   "source": [
    "# Embeddings for Recommendations\n",
    "\n",
    "Here I use a move rating data set from Kaggle.\n",
    "In this notebook I will derive embeddings for users and movies\n",
    "and these will be the ingredients of a matrix factorization\n",
    "of the full rating matrix.\n",
    "\n",
    "We will train a simple Neural Net using Pytorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b2313637",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch.cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d89d633f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9fb9dffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "!export CUDA_LAUNCH_BLOCKING=1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "002f08c1",
   "metadata": {},
   "source": [
    "### Note: I am going to use my GPU card ... or try to anyway."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9c1a4b36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device in use: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"Device in use:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e216cfa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Read in the data and show shape and head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6996373a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(26024289, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>110</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1425941529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>147</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1425942435</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  movieId  rating   timestamp\n",
       "0       1      110     1.0  1425941529\n",
       "1       1      147     4.5  1425942435"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdf = pd.read_csv(\"ratings.csv\")\n",
    "print(rdf.shape)\n",
    "rdf.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "19f57bba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max userId 270896 num users 270896\n",
      "max movieId 176275 num movies 45115\n"
     ]
    }
   ],
   "source": [
    "print(f\"max userId {rdf.userId.max()} num users {rdf.userId.nunique()}\")\n",
    "print(f\"max movieId {rdf.movieId.max()} num movies {rdf.movieId.nunique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "398b54ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7840094, 4)\n"
     ]
    }
   ],
   "source": [
    "subsample = True\n",
    "if subsample:\n",
    "    max_user = 100000\n",
    "    max_movie = 20000\n",
    "    df = rdf.copy()\n",
    "    df = df.loc[df.movieId <= max_movie]\n",
    "    df = df.loc[df.userId <= max_user]\n",
    "    print(df.shape)    \n",
    "else:\n",
    "    df = rdf.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b978048f",
   "metadata": {},
   "source": [
    "## Partition the dataset\n",
    "into train, val and test.\n",
    "We can use val to tune the hyper parameters.\n",
    "\n",
    "Test will be held out until all training is done.\n",
    "\n",
    "We could use the sklearn function but I find this just as easy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f1aac548",
   "metadata": {},
   "outputs": [],
   "source": [
    "def partition(df, pct=0.1):\n",
    "    size = int(np.floor(df.shape[0])*0.1)\n",
    "    idx = list(np.random.choice(df.index, size, replace=False))\n",
    "    subset = df.filter(items=idx, axis=0)\n",
    "    rest = df.drop(index = idx)\n",
    "    return subset, rest\n",
    "\n",
    "testdf, val_train = partition(df, 0.1)\n",
    "valdf, traindf = partition(val_train, 0.1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3f59253",
   "metadata": {},
   "source": [
    "## Dataset and dataloader\n",
    "I want to use mini-batch training so we need a dataset\n",
    "and a dataloader.\n",
    "\n",
    "I adapted some code for converting a pandas dataframe into a dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "599bfbfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, dataframe):\n",
    "        self.dataframe = dataframe\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        row = self.dataframe.iloc[index].to_numpy()\n",
    "        userid = int(row[0])\n",
    "        movieid = int(row[1])\n",
    "        rating = np.float32(row[2])\n",
    "        return userid, movieid, rating\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "\n",
    "traindata = CustomDataset(dataframe=traindf)\n",
    "train_dataloader = DataLoader(traindata, batch_size=1024)\n",
    "\n",
    "valdata = CustomDataset(dataframe=valdf)\n",
    "val_dataloader = DataLoader(valdata, batch_size=1024)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8e14b13",
   "metadata": {},
   "source": [
    "## the Model\n",
    "The model is fairly simple: 2 embedding layers, \n",
    "    one each for users and movies.\n",
    "    \n",
    "At the end of \"froward\" we simply do the dot product."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d4e8e124",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MF(nn.Module):\n",
    "    def __init__(self, n_users, n_movies, emb_size=100):\n",
    "        super(MF, self).__init__()\n",
    "        self.user_emb = nn.Embedding(n_users, emb_size)\n",
    "        self.movie_emb = nn.Embedding(n_movies, emb_size)\n",
    "        # initializing our matrices with a positive number generally will yield better results\n",
    "        self.user_emb.weight.data.uniform_(0, 0.5)\n",
    "        self.movie_emb.weight.data.uniform_(0, 0.5)\n",
    "    def forward(self, users, movies):\n",
    "        print(\"in forward\")\n",
    "        print(users, movies)\n",
    "        u = self.user_emb(users)\n",
    "        m = self.movie_emb(movies)\n",
    "        print ( u, m)\n",
    "        return (u * m).sum(1)  # taking the dot product\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99c0ff82",
   "metadata": {},
   "source": [
    "## instantiate the Model\n",
    "and push it to the gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2ec19318",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using cuda\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[0;32mIn [20]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available():\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124musing cuda\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 6\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mnext\u001b[39m(model\u001b[38;5;241m.\u001b[39mparameters())\u001b[38;5;241m.\u001b[39mis_cuda)\n",
      "File \u001b[0;32m~/anaconda3/envs/recommendations/lib/python3.10/site-packages/torch/nn/modules/module.py:927\u001b[0m, in \u001b[0;36mModule.to\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    923\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    924\u001b[0m                     non_blocking, memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format)\n\u001b[1;32m    925\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, non_blocking)\n\u001b[0;32m--> 927\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/recommendations/lib/python3.10/site-packages/torch/nn/modules/module.py:579\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    577\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_apply\u001b[39m(\u001b[38;5;28mself\u001b[39m, fn):\n\u001b[1;32m    578\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 579\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    581\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    582\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    583\u001b[0m             \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    584\u001b[0m             \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    589\u001b[0m             \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    590\u001b[0m             \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/recommendations/lib/python3.10/site-packages/torch/nn/modules/module.py:602\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    598\u001b[0m \u001b[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[1;32m    599\u001b[0m \u001b[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[1;32m    600\u001b[0m \u001b[38;5;66;03m# `with torch.no_grad():`\u001b[39;00m\n\u001b[1;32m    601\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 602\u001b[0m     param_applied \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    603\u001b[0m should_use_set_data \u001b[38;5;241m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[1;32m    604\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m should_use_set_data:\n",
      "File \u001b[0;32m~/anaconda3/envs/recommendations/lib/python3.10/site-packages/torch/nn/modules/module.py:925\u001b[0m, in \u001b[0;36mModule.to.<locals>.convert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    922\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m convert_to_format \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m t\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m5\u001b[39m):\n\u001b[1;32m    923\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    924\u001b[0m                 non_blocking, memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format)\n\u001b[0;32m--> 925\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_floating_point\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_complex\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1."
     ]
    }
   ],
   "source": [
    "n_users = rdf.userId.nunique()\n",
    "n_movies = rdf.movieId.nunique()\n",
    "model = MF(n_users, n_movies, emb_size=100)\n",
    "if torch.cuda.is_available():\n",
    "    print(\"using cuda\")\n",
    "    model = model.to(device)\n",
    "    print(next(model.parameters()).is_cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2196c2a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " epoch 0\n",
      " 0 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../aten/src/ATen/native/cuda/Indexing.cu:975: indexSelectLargeIndex: block: [114,0,0], thread: [64,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:975: indexSelectLargeIndex: block: [114,0,0], thread: [65,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:975: indexSelectLargeIndex: block: [114,0,0], thread: [66,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:975: indexSelectLargeIndex: block: [114,0,0], thread: [67,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:975: indexSelectLargeIndex: block: [114,0,0], thread: [68,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:975: indexSelectLargeIndex: block: [114,0,0], thread: [69,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:975: indexSelectLargeIndex: block: [114,0,0], thread: [70,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:975: indexSelectLargeIndex: block: [114,0,0], thread: [71,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:975: indexSelectLargeIndex: block: [114,0,0], thread: [72,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:975: indexSelectLargeIndex: block: [114,0,0], thread: [73,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:975: indexSelectLargeIndex: block: [114,0,0], thread: [74,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:975: indexSelectLargeIndex: block: [114,0,0], thread: [75,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:975: indexSelectLargeIndex: block: [114,0,0], thread: [76,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:975: indexSelectLargeIndex: block: [114,0,0], thread: [77,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:975: indexSelectLargeIndex: block: [114,0,0], thread: [78,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:975: indexSelectLargeIndex: block: [114,0,0], thread: [79,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:975: indexSelectLargeIndex: block: [114,0,0], thread: [80,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:975: indexSelectLargeIndex: block: [114,0,0], thread: [81,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:975: indexSelectLargeIndex: block: [114,0,0], thread: [82,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:975: indexSelectLargeIndex: block: [114,0,0], thread: [83,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:975: indexSelectLargeIndex: block: [114,0,0], thread: [84,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:975: indexSelectLargeIndex: block: [114,0,0], thread: [85,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:975: indexSelectLargeIndex: block: [114,0,0], thread: [86,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:975: indexSelectLargeIndex: block: [114,0,0], thread: [87,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:975: indexSelectLargeIndex: block: [114,0,0], thread: [88,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:975: indexSelectLargeIndex: block: [114,0,0], thread: [89,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:975: indexSelectLargeIndex: block: [114,0,0], thread: [90,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:975: indexSelectLargeIndex: block: [114,0,0], thread: [91,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:975: indexSelectLargeIndex: block: [114,0,0], thread: [92,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:975: indexSelectLargeIndex: block: [114,0,0], thread: [93,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:975: indexSelectLargeIndex: block: [114,0,0], thread: [94,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:975: indexSelectLargeIndex: block: [114,0,0], thread: [95,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[0;32mIn [12]\u001b[0m, in \u001b[0;36m<cell line: 10>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     32\u001b[0m y_hat \u001b[38;5;241m=\u001b[39m model(users, movies)\n\u001b[1;32m     33\u001b[0m loss \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mmse_loss(y_hat, ratings)\n\u001b[0;32m---> 34\u001b[0m train_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mround(\u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;241m4\u001b[39m)\u001b[38;5;241m/\u001b[39m users\u001b[38;5;241m.\u001b[39msize()[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     36\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()  \u001b[38;5;66;03m# reset gradient\u001b[39;00m\n\u001b[1;32m     37\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1."
     ]
    }
   ],
   "source": [
    "# training\n",
    "epochs=4\n",
    "lr=0.01\n",
    "wd=0.0\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=wd)\n",
    "#model.to(device)\n",
    "#optimizer.to(device)\n",
    "#train_dataloader.to(device)\n",
    "model.train()\n",
    "for ei in range(epochs):\n",
    "    print(f\" epoch {ei}\")\n",
    "    if False:\n",
    "        userIds = torch.LongTensor(train.userId.values).to(device)\n",
    "        movieIds = torch.LongTensor(train.movieId.values).to(device)\n",
    "        ratings = torch.FloatTensor(train.rating.values).to(device)\n",
    "        print(userIds)\n",
    "        y_hat = model(userIds, movieIds)\n",
    "        loss = F.mse_loss(y_hat, ratings)\n",
    "        train_loss += np.round(loss.item(), 4)/ users.size[0]\n",
    "        optimizer.zero_grad()  # reset gradient\n",
    "        loss.backward()\n",
    "        optimizer.step()        \n",
    "    if True:\n",
    "        train_loss = 0.0\n",
    "        for tbi, data in enumerate(train_dataloader):\n",
    "            if tbi % 512 == 0:\n",
    "                print(f\" {tbi} {train_loss}\")\n",
    "            users, movies, ratings = data\n",
    "            users = users.cuda()\n",
    "            movies = movies.cuda()\n",
    "            ratings = ratings.cuda()\n",
    "            y_hat = model(users, movies)\n",
    "            loss = F.mse_loss(y_hat, ratings)\n",
    "            train_loss += np.round(loss.item(), 4)/ users.size()[0]\n",
    "\n",
    "            optimizer.zero_grad()  # reset gradient\n",
    "            loss.backward()\n",
    "            optimizer.step() \n",
    "\n",
    "    print(\"done with training\")\n",
    "    val_loss = 0.0\n",
    "    if True:\n",
    "        for i, data in enumerate(val_dataloader):\n",
    "            users, movies, ratings = data\n",
    "            users = users.cuda()\n",
    "            movies = movies.cuda()\n",
    "            ratings = ratings.cuda()\n",
    "            y_hat = model(users, movies)\n",
    "            loss = F.mse_loss(y_hat, ratings)\n",
    "            val_loss += np.round(loss.item(), 4)/ users.size()[0]\n",
    "\n",
    "    print(f\" train loss {train_loss}  val loss {val_loss}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "83ffe10c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Tensor"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a127ef5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d497e908",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40ba10f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddf472ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ee4a39d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8691cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(users)\n",
    "print(users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d639d1a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, df):\n",
    "    model.eval()\n",
    "    users = torch.LongTensor(df.userId.values)\n",
    "    movies = torch.LongTensor(df.movieId.values)\n",
    "    ratings = torch.FloatTensor(df.rating.values)\n",
    "    y_hat = model(users, movies)\n",
    "    loss = F.mse_loss(y_hat, ratings)\n",
    "    return  loss.item()\n",
    "val_err = test_model(model, val)\n",
    "test_err = test_model(model, test)    \n",
    "print(val_err, test_err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b3f70e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "user = torch.tensor([10])\n",
    "games = torch.tensor(game_ratings['movieId'].unique().tolist())\n",
    "predictions = model(user, games).tolist()\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a985a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_predictions = [i/max(predictions)*10 for i in predictions]\n",
    "print(normalized_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8318c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sortedIndices = predictions.argsort()\n",
    "recommendations = dataset['Title'].unique()[sortedIndices][:30]  # taking top 30\n",
    "print(recommendations)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "recommendations",
   "language": "python",
   "name": "recommendations"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
